{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FJada/artificial-intelligence/blob/main/Bike_Rides_and_the_Poisson_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6AmWVM-oZ2r"
      },
      "source": [
        "# Bike Rides and the Poisson Model\n",
        "\n",
        "To help the urban planners, you are called to model the daily bike rides in NYC using [this dataset](https://gist.github.com/sachinsdate/c17931a3f000492c1c42cf78bf4ce9fe/archive/7a5131d3f02575668b3c7e8c146b6a285acd2cd7.zip).  The dataset contains date, day of the week, high and low temp, precipitation and bike ride couunts as columns. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mmt-qSvoZ2u"
      },
      "source": [
        "## Maximum Likelihood I \n",
        " \n",
        "The obvious choice in distributions is the [Poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution) which depends only on one parameter, Î», which is the average number of occurrences per interval. We want to estimate this parameter using Maximum Likelihood Estimation.\n",
        "\n",
        "Implement a Gradient Descent algorithm from scratch that will estimate the Poisson distribution according to the Maximum Likelihood criterion. Plot the estimated mean vs iterations to showcase convergence towards the true mean. \n",
        "\n",
        "References: \n",
        "\n",
        "1. [This blog post](https://towardsdatascience.com/the-poisson-process-everything-you-need-to-know-322aa0ab9e9a). \n",
        "\n",
        "2. [This blog post](https://towardsdatascience.com/understanding-maximum-likelihood-estimation-fa495a03017a) and note the negative  log likelihood function.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Resources used:\n",
        "\n",
        "https://towardsdatascience.com/understanding-maximum-likelihood-estimation-fa495a03017a\n",
        "\n",
        "https://www.statology.org/mle-poisson-distribution/\n",
        "\n",
        "https://towardsdatascience.com/the-poisson-process-everything-you-need-to-know-322aa0ab9e9a\n",
        "\n",
        "https://mlstory.org/optimization.html\n",
        "\n",
        "https://medium.com/computronium/gradient-based-optimizations-under-the-deep-learning-lens-ac99e62289a8"
      ],
      "metadata": {
        "id": "FU_nfPo5xuhC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xY8-dbxoZ2v"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "from math import lambda \n",
        "\n",
        "#get data\n",
        "df = pd.read_csv(\"nyc_bb_bicyclist_counts.csv\")\n",
        "bicyclist = df[\"bicyclist\"]\n",
        "\n",
        "def poisson_distribution(x):\n",
        "  return ((lambda**x * np.exp(-lambda)) / (math.factorial(x)))\n",
        "\n",
        "def negative_log_likelihood(bicyclist, parameters):\n",
        "  n = len(bicyclists) \n",
        "  lambda = parameters\n",
        "  return (n * lambda  + np.sum(np.log(math.factorial(x))) - np.log(lambda) * np.sum(math.factorial(x)))\n",
        "\n",
        "\n",
        "def gradient(bicyclist, parameters):\n",
        "  lambda = parameters\n",
        "  n = len(bicyclists) \n",
        "  partial_derivative_lambda = -n  + 1/lambda * np.sum(x)\n",
        "  return np.array([partial_derivative_lambda])\n",
        "\n",
        "def gradient_descent(bicyclist, learning_rate = 0.01, tolerance = 1e-4, iterations = 1000):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  curr_lambda = np.array([lambda])\n",
        "  for i in range(iterations):\n",
        "    new_lambda = = curr_lambda.copy()\n",
        "    difference = gradient(bicyclist, new_lambda) * -learning_rate \n",
        "    if new_lambda[0] < tolerance:\n",
        "      break\n",
        "     new_lambda += differnece\n",
        "  return  new_lambda\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrlIARbioZ2w"
      },
      "source": [
        "## Maximum Likelihood II\n",
        "\n",
        "A colleague of yours suggest that the parameter $\\lambda$ must be itself dependent on the weather and other factors since people bike when its not raining. Assume that you model $\\lambda$ as \n",
        "\n",
        "$$\\lambda_i = \\exp(\\mathbf w^T \\mathbf x_i)$$\n",
        "\n",
        "where $\\mathbf x_i$ is one of the example features and $\\mathbf w$ is a set of parameters. \n",
        "\n",
        "Train the model with SGD with this assumption and compare the MSE of the predictions with the `Maximum Likelihood I` approach. \n",
        "\n",
        "You may want to use [this partial derivative of the log likelihood function](http://home.cc.umanitoba.ca/~godwinrt/7010/poissonregression.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QV3WZRBeoZ2x"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from math import lambda \n",
        "\n",
        "#get data\n",
        "df = pd.read_csv(\"nyc_bb_bicyclist_counts.csv\")\n",
        "bicyclist = df[\"bicyclist\"]\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "7d6993cb2f9ce9a59d5d7380609d9cb5192a9dedd2735a011418ad9e827eb538"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
